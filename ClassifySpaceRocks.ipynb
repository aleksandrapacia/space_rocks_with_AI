{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI model to classify space rocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_sampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22228\\1909679731.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m# create a trainloader to load 20 percent of the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# create a testloader to load 80 percent of the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_split_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m# PRINT TYPE OF ROCKS THAT ARE INCLUDED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22228\\1909679731.py\u001b[0m in \u001b[0;36mload_split_train_test\u001b[1;34m(data_dir, valid_size)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;31m#create loaders to load 16 images from TRAIN and TEST folders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m#images are chosen based on SHUFFLED INDEX LISTS and by using samplers (?)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mtrainloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[0mtestloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_sampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_sampler' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# where data is\n",
    "data_dir = './Data'\n",
    "# read data-> crop&resize the images -> split data into 2 groups: TEST and TRAIN\n",
    "def load_split_train_test(data_dir, valid_size = .2):\n",
    "    #transform the images to train the model\n",
    "    train_transforms = transforms.Compose([ \n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # transform images to test the model\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # two variables for folders with TRAINING and TESTING images\n",
    "    train_data = datasets.ImageFolder(data_dir, transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
    "\n",
    "    # get number of images in the TRAINING FOLDER\n",
    "    num_train = len(train_data)\n",
    "\n",
    "    # list of numbers from 0 -> number of (training images - 1) -> e.g for 6 images [0,1,2,3,4,5]\n",
    "    # indices - indeksy (plural)\n",
    "    indices = list(range(num_train))\n",
    "\n",
    "    # if valid_size == .2 -> find the index of the image that represents 20% of the data\n",
    "\n",
    "    # if there are 10 images -> a split would result in 2 (because it's 20 %)\n",
    "\n",
    "    # split = int(np.floor(valid_size * num_train)) -> int(np.floor(2)) -> int(2) -> 2\n",
    "    split = int(np.floor(valid_size *  num_train))\n",
    "\n",
    "    # shuffle the indices randomly\n",
    "    # so 10 images might look like this : [3,1,6,9,0,2,4,8,7,5]\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "    # so we shuffled the indices randomly\n",
    "    # we grab 20 percent of shuffled indices to store them in the TRAINING INDEX LIST\n",
    "    # then we grab the remainder (so 80 percent) shuffled indices to storem them in TESTING INDEX LIST\n",
    "    # result :\n",
    "    # train_idx is the list [1,5] (20 %)\n",
    "    # test_idx is the list [4,6,7,1,3,9,8] (80 %)\n",
    "    train_idx, test_idx = indices[split:] , indices[:split]\n",
    "\n",
    "    # create loaders to randomly grab items from training and testing indices\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    #create loaders to load 16 images from TRAIN and TEST folders\n",
    "    #images are chosen based on SHUFFLED INDEX LISTS and by using samplers (?)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
    "\n",
    "    # returns loaders so that you can grab images randomly from the training and testing data folders\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "# using function which shuffles images\n",
    "# create a trainloader to load 20 percent of the images\n",
    "# create a testloader to load 80 percent of the images\n",
    "trainloader, testloader = load_split_train_test(data_dir, .2)\n",
    "\n",
    "# PRINT TYPE OF ROCKS THAT ARE INCLUDED\n",
    "print(trainloader.dataset.classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
